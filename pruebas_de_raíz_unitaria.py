# -*- coding: utf-8 -*-
"""Pruebas de ra√≠z unitaria

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aAZbxSWAysfuGzuyzxke0vhdVrzfD4To
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import yfinance as yf
from statsmodels.tsa.stattools import adfuller
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from datetime import datetime
import matplotlib.dates as mdates

# Set the style for our plots
sns.set_style('whitegrid')
plt.rcParams['figure.figsize'] = (14, 8)
plt.rcParams['axes.labelsize'] = 14
plt.rcParams['axes.titlesize'] = 16
plt.rcParams['xtick.labelsize'] = 12
plt.rcParams['ytick.labelsize'] = 12

# Download stock data from Yahoo Finance
start_date = '2019-11-29'
end_date = datetime.now().strftime('%Y-%m-%d')
tickers = ['TSLA', 'AAPL', 'NVDA']

# Fetch the data - specifically request columns to avoid errors
data = yf.download(tickers, start=start_date, end=end_date)
# Extract closing prices - using 'Close' instead of 'Adj Close'
close_data = data['Close']
close_data.columns = tickers

print(f"Data ranges from {close_data.index.min().strftime('%Y-%m-%d')} to {close_data.index.max().strftime('%Y-%m-%d')}")
print(f"Number of trading days: {len(close_data)}")

# Calculate daily returns
returns = close_data.pct_change().dropna()

# Calculate log returns
log_returns = np.log(close_data / close_data.shift(1)).dropna()

# Function to perform random walk simulation
def simulate_random_walk(returns, ticker, n_simulations=100, n_days=252):
    """
    Simulate random walks based on historical returns
    """
    current_price = close_data[ticker].iloc[-1]
    historical_volatility = returns[ticker].std()
    historical_drift = returns[ticker].mean()

    # Simulate random walks
    simulations = np.zeros((n_days, n_simulations))

    for i in range(n_simulations):
        prices = [current_price]
        for _ in range(n_days):
            # Daily return with drift and stochastic component
            daily_return = historical_drift + historical_volatility * np.random.normal()
            prices.append(prices[-1] * (1 + daily_return))
        simulations[:, i] = prices[1:]  # Skip the initial price

    return simulations

# Function to perform Augmented Dickey-Fuller test
def adf_test(series, ticker):
    """
    Perform ADF test and print results
    """
    result = adfuller(series.dropna())
    print(f"ADF Test Results for {ticker}:")
    print(f"ADF Statistic: {result[0]:.4f}")
    print(f"p-value: {result[1]:.4f}")
    print(f"Critical Values:")
    for key, value in result[4].items():
        print(f"\t{key}: {value:.4f}")

    # Interpret the results
    if result[1] <= 0.05:
        print(f"Strong evidence against the null hypothesis")
        print(f"Reject the null hypothesis")
        print(f"Data is stationary")
    else:
        print(f"Weak evidence against the null hypothesis")
        print(f"Fail to reject the null hypothesis")
        print(f"Data is non-stationary")
    print("\n")

    return result

# Create a figure for stock price trends
plt.figure(figsize=(14, 8))
for ticker in tickers:
    plt.plot(close_data.index, close_data[ticker] / close_data[ticker].iloc[0] * 100, label=ticker)
plt.title('Stock Price Trends (Normalized to 100)')
plt.ylabel('Normalized Price')
plt.xlabel('Date')
plt.legend()
plt.grid(True)
plt.savefig('stock_trends.png', dpi=300, bbox_inches='tight')
plt.show()

# Perform Random Walk Simulations for each ticker
plt.figure(figsize=(18, 12))

for i, ticker in enumerate(tickers):
    plt.subplot(3, 1, i+1)

    # Get the simulation data
    simulations = simulate_random_walk(returns, ticker, n_simulations=50, n_days=252)

    # Plot the simulations
    current_price = close_data[ticker].iloc[-1]
    forecast_dates = pd.date_range(start=close_data.index[-1], periods=253, freq='B')[1:]

    for sim in range(simulations.shape[1]):
        plt.plot(forecast_dates, simulations[:, sim], linewidth=0.8, alpha=0.5, color='blue')

    # Plot the historical data
    plt.plot(close_data.index[-252:], close_data[ticker].iloc[-252:], color='black', linewidth=2, label='Historical')

    # Calculate percentiles for confidence intervals
    lower_5 = np.percentile(simulations, 5, axis=1)
    upper_95 = np.percentile(simulations, 95, axis=1)

    plt.fill_between(forecast_dates, lower_5, upper_95, color='red', alpha=0.15, label='90% Confidence Interval')

    plt.title(f'{ticker} - Random Walk Simulation (1 Year Forecast)')
    plt.ylabel('Stock Price ($)')
    plt.xlabel('Date')
    plt.legend()

    # Format the date axis
    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))
    plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=3))
    plt.grid(True)

plt.tight_layout()
plt.savefig('random_walk_simulations.png', dpi=300, bbox_inches='tight')
plt.show()

# Perform Unit Root Tests (ADF Test)
print("=== Unit Root Tests (Augmented Dickey-Fuller) ===")
print("--- Price Series ---")
adf_results_price = {}
for ticker in tickers:
    adf_results_price[ticker] = adf_test(close_data[ticker], ticker)

print("--- Log Returns ---")
adf_results_returns = {}
for ticker in tickers:
    adf_results_returns[ticker] = adf_test(log_returns[ticker], ticker)

# Create Correlograms
plt.figure(figsize=(18, 12))

for i, ticker in enumerate(tickers):
    # ACF Plot
    plt.subplot(3, 2, 2*i+1)
    plot_acf(log_returns[ticker].dropna(), lags=40, alpha=0.05, title=f'ACF for {ticker} Log Returns')
    plt.grid(True)

    # PACF Plot
    plt.subplot(3, 2, 2*i+2)
    plot_pacf(log_returns[ticker].dropna(), lags=40, alpha=0.05, title=f'PACF for {ticker} Log Returns')
    plt.grid(True)

plt.tight_layout()
plt.savefig('correlograms.png', dpi=300, bbox_inches='tight')
plt.show()

# Cross-correlation analysis
plt.figure(figsize=(14, 10))

# Create a correlation matrix and heatmap
corr_matrix = log_returns.corr()
mask = np.triu(np.ones_like(corr_matrix, dtype=bool))
sns.heatmap(corr_matrix, annot=True, mask=mask, cmap='coolwarm', vmin=-1, vmax=1,
            linewidths=0.5, cbar_kws={"shrink": .8})
plt.title('Correlation Matrix of Log Returns')
plt.tight_layout()
plt.savefig('correlation_matrix.png', dpi=300, bbox_inches='tight')
plt.show()

# Plot return distributions
plt.figure(figsize=(14, 8))
for ticker in tickers:
    sns.kdeplot(log_returns[ticker], label=ticker)
plt.title('Distribution of Log Returns')
plt.xlabel('Daily Log Return')
plt.ylabel('Density')
plt.legend()
plt.grid(True)
plt.savefig('return_distributions.png', dpi=300, bbox_inches='tight')
plt.show()

# Summary statistics
print("\n=== Summary Statistics for Log Returns ===")
print(log_returns.describe())

# Volatility analysis
rolling_std = log_returns.rolling(window=21).std() * np.sqrt(252)  # Annualized
plt.figure(figsize=(14, 8))
for ticker in tickers:
    plt.plot(rolling_std.index, rolling_std[ticker], label=ticker)
plt.title('21-Day Rolling Annualized Volatility')
plt.ylabel('Volatility')
plt.xlabel('Date')
plt.legend()
plt.grid(True)
plt.savefig('volatility.png', dpi=300, bbox_inches='tight')
plt.show()